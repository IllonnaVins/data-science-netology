{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции «Функции потерь и оптимизация»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T17:04:33.949399Z",
     "start_time": "2020-06-15T17:04:33.929268Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100,))"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "filter = y != 0\n",
    "\n",
    "X = X[filter]\n",
    "y = y[filter]\n",
    "\n",
    "X.shape, y.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Меняю значения target на 0 и 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.where(y == 2, 1, 0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(coefs, x):    \n",
    "    return 1. / (1. + np.exp( -(x.dot(coefs[:4]) + coefs[-1]) ) )\n",
    "\n",
    "def predict_class(coefs, x):\n",
    "    probas = predict_proba(coefs, x)\n",
    "    return (probas > 0.5).astype(np.float)\n",
    "\n",
    "def bce_loss(coefs, x, y):\n",
    "    probas = predict_proba(coefs, x)\n",
    "    filter_ones = y == 1\n",
    "    loss = -1. * (np.sum(np.log(probas[filter_ones])) + np.sum(np.log(1. - probas[~filter_ones]))) / len(y)\n",
    "    return loss\n",
    "\n",
    "def grad(coefs, x, y):\n",
    "    probas = predict_proba(coefs, x)\n",
    "    delta = probas - y\n",
    "    modified_x = x.T * delta\n",
    "    deltas = np.mean(modified_x, axis=1)\n",
    "    return deltas, np.mean(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обучение методом градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22853962e+00, -2.68731458e-04,  6.70880744e-01, -2.14370593e-01,\n",
       "        3.98443978e-01])"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COEFS = np.random.randn(5) # в дальнейшем везде использую такие же коэффициенты для сравнения результата\n",
    "\n",
    "COEFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_sgd(cf, x, y, num_epochs=20, learning_rate=0.1):\n",
    "    losses = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        grad_coefs, grad_bias = grad(cf, x, y)\n",
    "        \n",
    "        cf[:-1] = cf[:-1] - learning_rate * grad_coefs\n",
    "        cf[-1] = cf[-1] - learning_rate * grad_bias\n",
    "        \n",
    "        loss = bce_loss(cf, x, y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return losses, cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2169465100949224,\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss(COEFS, X, y), predict_class(COEFS, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5892392571136057,\n",
       "  0.5745467487760421,\n",
       "  0.5622807431464154,\n",
       "  0.5554970967015077,\n",
       "  0.5497310419460713,\n",
       "  0.5456092316960808,\n",
       "  0.5419901431737402,\n",
       "  0.5389525580283481,\n",
       "  0.536160555218131,\n",
       "  0.5335960114116806,\n",
       "  0.5311515060406039,\n",
       "  0.5288058885567719,\n",
       "  0.5265226412806712,\n",
       "  0.5242896446898996,\n",
       "  0.5220938849080539,\n",
       "  0.5199296053220008,\n",
       "  0.5177919727222011,\n",
       "  0.5156784341296673,\n",
       "  0.5135870916361078,\n",
       "  0.5115167985042435],\n",
       " array([-0.98079527,  0.06119298,  1.14572658,  0.05516204,  0.39196385]))"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses, new_coefs = learn_sgd(COEFS, X, y)\n",
    "\n",
    "losses, new_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5115167985042435,\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss(new_coefs, X, y), predict_class(new_coefs, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обучение методом nesterov momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22853962e+00, -2.68731458e-04,  6.70880744e-01, -2.14370593e-01,\n",
       "        3.98443978e-01])"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COEFS = np.array([-1.22853962e+00, -2.68731458e-04,  6.70880744e-01, -2.14370593e-01, 3.98443978e-01])\n",
    "COEFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2169465142304428,\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss(COEFS, X, y), predict_class(COEFS, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_nesterov(coefs, x, y, num_epochs=20, learning_rate=0.1, momentum = 0.9):\n",
    "    losses = []\n",
    "    \n",
    "    v1 = 0 # начальная скорость изменения для первых 4-х коэффициентов\n",
    "    v2 = 0 # начальная скорость изменения для последнего коэффициента\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "#         Вычисляю прогнозную точку прогнозную точку и градиент для неё\n",
    "        \n",
    "        cf_new1 = coefs[:-1] - momentum * v1\n",
    "        \n",
    "        cf_new2 = coefs[-1] - momentum * v2\n",
    "        \n",
    "        cf_new = np.append (cf_new1, cf_new2)\n",
    "        \n",
    "#         Вычисляю градиент для этой точки\n",
    "        \n",
    "        grad_coefs, grad_bias = grad(cf_new, x, y)\n",
    "        \n",
    "        \n",
    "#         Вычисляю скорость и направление и изменяем коэффициенты\n",
    "    \n",
    "        v1 = momentum * v1 + learning_rate * grad_coefs        \n",
    "        coefs[:-1] = coefs[:-1] - v1\n",
    "        \n",
    "        v2 = momentum * v2 + learning_rate * grad_bias\n",
    "        coefs[-1] = coefs[-1] - v2\n",
    "        \n",
    "        loss = bce_loss(coefs, x, y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return losses, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90757772  0.14449245  0.94179055 -0.11536258  0.4470397 ]\n",
      "[-0.88588687  0.14987877  0.99438463 -0.08541578  0.4457075 ]\n",
      "[-0.92171331  0.1267549   1.01234826 -0.06311965  0.43343532]\n",
      "[-0.8986586   0.12859779  1.0859893  -0.01802244  0.42881967]\n",
      "[-9.99204540e-01  7.21840166e-02  1.07117465e+00  1.67022151e-04\n",
      "  4.03170190e-01]\n",
      "[-0.91611301  0.09829538  1.20930743  0.0738846   0.40521269]\n",
      "[-1.06886143  0.01510896  1.17144568  0.09053949  0.36850736]\n",
      "[-0.9874044   0.03798751  1.32497255  0.17529684  0.3678093 ]\n",
      "[-1.14664901 -0.05038806  1.29689544  0.2004517   0.32785168]\n",
      "[-1.08223065 -0.03724312  1.44955681  0.28930402  0.32251866]\n",
      "[-1.24360321 -0.12828505  1.43008311  0.32111455  0.28058545]\n",
      "[-1.1855906  -0.11951709  1.58621587  0.41427325  0.27282995]\n",
      "[-1.34346265 -0.2102073   1.57627113  0.45193273  0.23027319]\n",
      "[-1.29663248 -0.20758691  1.72861897  0.54581671  0.21977585]\n",
      "[-1.447585   -0.29596277  1.72731265  0.587924    0.17757191]\n",
      "[-1.41108324 -0.29872267  1.87323028  0.68061497  0.16487302]\n",
      "[-1.55089917 -0.38249696  1.88071453  0.72625553  0.12407017]\n",
      "[-1.52671231 -0.39120631  2.01561716  0.81527029  0.10921863]\n",
      "[-1.65088368 -0.46798067  2.03248226  0.86374903  0.07088076]\n",
      "[-1.6405943  -0.48305229  2.1523671   0.94688496  0.0539595 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5892392579728467,\n",
       "  0.549483375315287,\n",
       "  0.5489392310117093,\n",
       "  0.5450562124645453,\n",
       "  0.5551003297257274,\n",
       "  0.5948656216866726,\n",
       "  0.5293356232313172,\n",
       "  0.5836129461854378,\n",
       "  0.49239752844644485,\n",
       "  0.5443442643546722,\n",
       "  0.4655821003386342,\n",
       "  0.5051181655028849,\n",
       "  0.43437937401506216,\n",
       "  0.46298013322114,\n",
       "  0.4054357958940296,\n",
       "  0.4222907655984705,\n",
       "  0.3774834601899183,\n",
       "  0.38386950233491873,\n",
       "  0.3516448341826587,\n",
       "  0.34985817419412407],\n",
       " array([-1.6405943 , -0.48305229,  2.1523671 ,  0.94688496,  0.0539595 ]))"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses, new_coefs = learn_sgd1(COEFS, X, y)\n",
    "\n",
    "losses, new_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34985817419412407,\n",
       " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss(new_coefs, X, y), predict_class(new_coefs, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обучение методом rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22853962e+00, -2.68731458e-04,  6.70880744e-01, -2.14370593e-01,\n",
       "        3.98443978e-01])"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COEFS = np.array([-1.22853962e+00, -2.68731458e-04,  6.70880744e-01, -2.14370593e-01, 3.98443978e-01])\n",
    "COEFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2169465142304428,\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss(COEFS, X, y), predict_class(COEFS, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_rmsprop(coefs, x, y, num_epochs=20, learning_rate=0.1, momentum = 0.9):\n",
    "    losses = []\n",
    "    \n",
    "    E1 = 0 # бегущее среднее для первых 4-х коэффициентов\n",
    "    E2 = 0 # бегущее среднее для последнего коэффициента\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "#         Считаю гнрадиенты\n",
    "        grad_coefs, grad_bias = grad(coefs, x, y)\n",
    "    \n",
    "#         Считаю новое среднее для каждого из 4-х коэффициентов, обновляю коэффициенты\n",
    "        E1_new = []        \n",
    "\n",
    "        for j, coef in enumerate(grad_coefs):            \n",
    "            e_prev = E1 if e == 0 else E1[j]    \n",
    "\n",
    "            e_new = momentum * e_prev + (1 - momentum) * (grad_coefs[j]**2)\n",
    "            \n",
    "            E1_new.append(e_new)\n",
    "            \n",
    "            coefs[j] = coefs[j] - learning_rate / math.sqrt(e_new + 10**-6) * grad_coefs[j]\n",
    "\n",
    "#         Обновляю E1\n",
    "        E1 = E1_new\n",
    "    \n",
    "#         Считаю новое среднее для последнего коэффициента, обновляю коэффициент\n",
    "    \n",
    "        E2 = momentum * E2 + (1 - momentum) * (grad_bias**2)\n",
    "        coefs[-1] = coefs[-1] - learning_rate / math.sqrt(E2 + 10**-6) * grad_bias  \n",
    "        \n",
    "        loss = bce_loss(coefs, x, y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return losses, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6196766282004638,\n",
       "  0.647687603925824,\n",
       "  0.6888399853672199,\n",
       "  0.6627117779357813,\n",
       "  0.6624969848984767,\n",
       "  0.617280893914502,\n",
       "  0.6109145555444904,\n",
       "  0.5855900592971486,\n",
       "  0.5839040882305945,\n",
       "  0.569913118691748,\n",
       "  0.5729218239967893,\n",
       "  0.5640860920434432,\n",
       "  0.5709096021771473,\n",
       "  0.562939624115715,\n",
       "  0.5714580059685381,\n",
       "  0.5606645991322922,\n",
       "  0.5681085229621021,\n",
       "  0.5537428543331082,\n",
       "  0.5592281583948978,\n",
       "  0.5436728962245178],\n",
       " array([-1.11333712,  0.01612747,  1.06640918,  0.45751202,  0.27974223]))"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses, new_coefs = learn_rmsprop(COEFS, X, y)\n",
    "\n",
    "losses, new_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5436728962245178,\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.]))"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss(new_coefs, X, y), predict_class(new_coefs, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "\n",
    "На этом дата сете лучшие результаты показывает nesterov momentum, но в целом результат зависит от попадания в первую точку и кол-ва итераций. Также результаты лучше, если обучать на первых двух группах ирисов (убирать y == 2, а не y == 0), там зависимость прослеживается лучше.\n",
    "\n",
    "<i>Хардкод начальных коэффициентов в двух последних методах для того, чтобы можно было наглядно сравнить результаты </i>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
